{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of New_Program.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjqLCa-M59Ii"
      },
      "source": [
        "Installing pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VCnp4ru5mVj"
      },
      "source": [
        "pip install pdfplumber"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4v324pF6Ceg"
      },
      "source": [
        "Installing fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OhGZAsH57WM"
      },
      "source": [
        "pip install fuzzywuzzy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AE4Z5b46ITG"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61jgEcDJ4-5O"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "import re\n",
        "import os\n",
        "import datetime\n",
        "import pdfplumber\n",
        "from fuzzywuzzy import fuzz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvjuQQSz6wre"
      },
      "source": [
        "User-defined Functions and Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNg94PXG61z6"
      },
      "source": [
        "# Matching Functions\n",
        "\n",
        "def match_or_not_vsp(fullname_day, fullname_ins, date_day, date_ins):\n",
        "\n",
        "    if date_day != date_ins:\n",
        "        return 0\n",
        "    else:    \n",
        "        name_parts_re = re.compile(r'([\\.\\'A-Z-]+)\\s+([\\.\\'A-Z-]+)')\n",
        "    \n",
        "        firstname_day = name_parts_re.search(fullname_day).group(1).strip()\n",
        "        lastname_day = name_parts_re.search(fullname_day).group(2).strip()\n",
        "\n",
        "        firstname_ins = name_parts_re.search(fullname_ins).group(1).strip()\n",
        "        lastname_ins = name_parts_re.search(fullname_ins).group(2).strip()\n",
        "\n",
        "        if firstname_day[:2] == firstname_ins[:2]:\n",
        "            if round(len(lastname_day) - ((fuzz.partial_ratio(lastname_day, lastname_ins) / 100) * len(lastname_day))) <= 1 or round(len(lastname_ins) - ((fuzz.partial_ratio(lastname_day, lastname_ins) / 100) * len(lastname_ins))) <= 1:\n",
        "                return 1\n",
        "            else:\n",
        "                return 0\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeIBI-29hoBy"
      },
      "source": [
        "Regular Expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm7eqMWPhrAg"
      },
      "source": [
        "# EyeMed (website)\n",
        "eyemed_claim_num_re = re.compile(r'Claim #: (\\d{12})')\n",
        "eyemed_name_re = re.compile(r'Member Name: ([A-Z- \\'\\.]+), ([A-Z- \\'\\.]+) Subscriber #:')\n",
        "eyemed_dos_re = re.compile(r'(\\d{2}/\\d{2}/\\d{2}) \\d{5}')\n",
        "eyemed_payments_re = re.compile(r'Totals -?\\$(\\d{1,3}\\.\\d{2}) -?\\$(\\d{1,3}\\.\\d{2}) -?\\$(\\d{1,3}\\.\\d{2}) -?\\$(\\d{1,3}\\.\\d{2}) -?\\$(\\d{1,3}\\.\\d{2}) -?\\$(\\d{1,3}\\.\\d{2}) -?\\$(\\d{1,3}\\.\\d{2}) -?\\$(\\d{1,3}\\.\\d{2})')\n",
        "eyemed_rename_re = re.compile(r'(\\d{2}/\\d{2}/\\d{2})')\n",
        "# EyeMed (scanned)\n",
        "scanned_eyemed_name_claim_num_re = re.compile(r'(\\d{11}) +(.+), +(.+)')\n",
        "scanned_eyemed_dos_re = re.compile(r'(\\d{1,2}/\\d{2}/\\d{4}) +\\d{4,5}')\n",
        "scanned_eyemed_payments_re = re.compile(r'Total Auth: +\\d{10} +\\d{0,3}[,\\.\\' ]*\\d{2} +\\d{0,3}[,\\.\\' ]*\\d{2} +\\d{0,3}[,\\.\\' ]*\\d{2} +\\d{0,3}[,\\.\\' ]*\\d{2} +\\d{0,3}[,\\.\\' ]*\\d{2} +\\d{0,3}[,\\.\\' ]*\\d{2} +\\d{0,3}[,\\.\\' ]*\\d{2} +(\\d{1,3})[,\\.\\' ]*\\d{2}')\n",
        "scanned_eyemed_rename_re = re.compile(r'Date: (\\d{1,2}/\\d{2}/\\d{4})')\n",
        "# VSP\n",
        "vsp_name_claim_num_re = re.compile(r'[ \\d]([-A-Z\\'\\.]+), ([A-Z-\\'\\.]*) (\\d{10})')\n",
        "vsp_dos_re = re.compile(r'(\\d{1,2}/\\d{2}/\\d{2}) +(\\d{5})')\n",
        "vsp_payments_re = re.compile(r'Totals -?\\d{1,3}\\.\\d{2} -?\\d{1,2}\\.\\d{2} -?\\d{1,2}\\.\\d{2} -?\\d{1,2}\\.\\d{2} -?\\d{1,2}\\.\\d{2} (-?\\d{1,2}\\.\\d{2})')\n",
        "vsp_rename_re = re.compile(r'^Date: (\\d{2}/\\d{2}/\\d{2})$')\n",
        "# Spectera\n",
        "spectera_name_re = re.compile(r'Patient Name: ([A-Z- \\'\\.]+) Subscriber: ([A-Z \\'-\\.]+) Group Name: .* Claim ID: (\\d{14})')\n",
        "spectera_dos_claim_num_re = re.compile(r'Patient Account: (\\w+) SubscriberID: .+ Received Date: (\\d{2}/\\d{2}/\\d{4})')\n",
        "spectera_payments_re = re.compile(r'SUBTOTAL THIS CLAIM \\d{1,3}\\.\\d{2} \\d{1,3}\\.\\d{2} \\d{1,3}\\.\\d{2} \\d{1,3}\\.\\d{2} (\\d{1,3}\\.\\d{2}) (\\d{1,3}\\.\\d{2}) \\d{1,3}\\.\\d{2}')\n",
        "spectera_long_name_re = re.compile(r'^([A-Z-\\'\\.]{2,200}).*')\n",
        "spectera_rename_re = re.compile(r'^(\\d{2}/\\d{2}/\\d{4}) \\$\\d{1,3}\\.\\d{2}$')\n",
        "# Med Mut\n",
        "medmut_name_claim_num_re = re.compile(r'PATIENT NAME: ([-A-Z\\'\\.]+), ([-A-Z\\'\\.]+) ID NUMBER: \\d+ CLAIM NUMBER: (\\d{12,14})')\n",
        "medmut_dos_re = re.compile(r'[N/A\\s]*(\\d{2}/\\d{2}/\\d{4}) \\d{5} \\d{1,3}\\.\\d{2}')\n",
        "medmut_payments_re = re.compile(r'CLAIM TOTAL \\d{1,3}\\.\\d{2} \\d{1,3}\\.\\d{2} (\\d{1,3})\\.\\d{2}')\n",
        "medmut_rename_re = re.compile(r'^(\\d{2}-\\d{2}-\\d{4})$')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ5S5chTL0pk"
      },
      "source": [
        "Renaming Day Sheets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee9OvyWjL4Sv"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/DaySheets/New Sheets')\n",
        "\n",
        "# Resetting file names\n",
        "for index, f in enumerate(os.listdir()):\n",
        "    os.rename(f, str(index))\n",
        "\n",
        "for f in os.listdir():\n",
        "    df = pd.read_excel(f)\n",
        "    same_name_count = 0\n",
        "    for ft in os.listdir():\n",
        "        if 'DaySheet_' + str(df['DATE'][0].to_pydatetime().date()) in ft:\n",
        "            same_name_count += 1\n",
        "    if same_name_count > 0:\n",
        "        os.rename(f, 'DaySheet_' + str(df['DATE'][0].to_pydatetime().date()) + ' (' + str(same_name_count) + ')')\n",
        "    else:\n",
        "        os.rename(f, 'DaySheet_' + str(df['DATE'][0].to_pydatetime().date()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XczH1j_NUQq7"
      },
      "source": [
        "Renaming EyeMed Sheets (Website)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klbNY0xUUT8Z"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/EyeMed_Sheets/New EyeMed Sheets')\n",
        "\n",
        "# Resetting file names\n",
        "for index, f in enumerate(os.listdir()):\n",
        "    os.rename(f, str(index))\n",
        "\n",
        "for f in os.listdir():\n",
        "    with pdfplumber.open(f) as pdf:\n",
        "        for line in pdf.pages[0].extract_text().split('\\n'):\n",
        "            if eyemed_rename_re.search(line):\n",
        "                same_name_count = 0\n",
        "                for ft in os.listdir():\n",
        "                    if 'EyeMed_' + str(datetime.datetime.strptime(eyemed_rename_re.search(line).group(1), '%m/%d/%y').date()) in ft:\n",
        "                        same_name_count += 1\n",
        "                if same_name_count > 0:\n",
        "                    os.rename(f, 'EyeMed_' + str(datetime.datetime.strptime(eyemed_rename_re.search(line).group(1), '%m/%d/%y').date()) + ' (' + str(same_name_count) + ')')\n",
        "                else:\n",
        "                    os.rename(f, 'EyeMed_' + str(datetime.datetime.strptime(eyemed_rename_re.search(line).group(1), '%m/%d/%y').date()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2-ZaadPUUiD"
      },
      "source": [
        "Renaming EyeMed Sheets (Scanned)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILlvbRiSUXjw"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/EyeMedMisc_Sheets')\n",
        "\n",
        "# Resetting file names\n",
        "for index, f in enumerate(os.listdir()):\n",
        "    os.rename(f, str(index))\n",
        "\n",
        "for f in os.listdir():\n",
        "    with pdfplumber.open(f) as pdf:\n",
        "        for line in pdf.pages[0].extract_text().split('\\n'):\n",
        "            if scanned_eyemed_rename_re.search(line):\n",
        "                same_name_count = 0\n",
        "                for ft in os.listdir():\n",
        "                    if 'Scanned_EyeMed_' + str(datetime.datetime.strptime(scanned_eyemed_rename_re.search(line).group(1).zfill(10), '%m/%d/%Y').date()) in ft:\n",
        "                        same_name_count += 1\n",
        "                if same_name_count > 0:\n",
        "                    os.rename(f, 'Scanned_EyeMed_' + str(datetime.datetime.strptime(scanned_eyemed_rename_re.search(line).group(1).zfill(10), '%m/%d/%Y').date()) + ' (' + str(same_name_count) + ')')\n",
        "                else:\n",
        "                    os.rename(f, 'Scanned_EyeMed_' + str(datetime.datetime.strptime(scanned_eyemed_rename_re.search(line).group(1).zfill(10), '%m/%d/%Y').date()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-6ZAi1pUYGs"
      },
      "source": [
        "Renaming VSP Sheets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_1vZwc_Ubni"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/VSP_Sheets/New VSP Sheets')\n",
        "\n",
        "# Resetting file names\n",
        "for index, f in enumerate(os.listdir()):\n",
        "    os.rename(f, str(index))\n",
        "\n",
        "for f in os.listdir():\n",
        "    with pdfplumber.open(f) as pdf:\n",
        "        for line in pdf.pages[0].extract_text().split('\\n'):\n",
        "            if vsp_rename_re.search(line):\n",
        "                same_name_count = 0\n",
        "                for ft in os.listdir():\n",
        "                    if 'VSP_' + str(datetime.datetime.strptime(vsp_rename_re.search(line).group(1), '%m/%d/%y').date()) in ft:\n",
        "                        same_name_count += 1\n",
        "                if same_name_count > 0:\n",
        "                    os.rename(f, 'VSP_' + str(datetime.datetime.strptime(vsp_rename_re.search(line).group(1), '%m/%d/%y').date()) + ' (' + str(same_name_count) + ')')\n",
        "                else:\n",
        "                    os.rename(f, 'VSP_' + str(datetime.datetime.strptime(vsp_rename_re.search(line).group(1), '%m/%d/%y').date()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn5nzHoWUcGe"
      },
      "source": [
        "Renaming Spectera Sheets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnIJnx7NUf8H"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/Spectera_Sheets/New Spectera Sheets')\n",
        "\n",
        "# Resetting file names\n",
        "for index, f in enumerate(os.listdir()):\n",
        "    os.rename(f, str(index))\n",
        "\n",
        "for f in os.listdir():\n",
        "    with pdfplumber.open(f) as pdf:\n",
        "        for line in pdf.pages[0].extract_text().split('\\n'):\n",
        "            if spectera_rename_re.search(line):\n",
        "                same_name_count = 0\n",
        "                for ft in os.listdir():\n",
        "                    if 'Spectera_' + str(datetime.datetime.strptime(spectera_rename_re.search(line).group(1), '%m/%d/%Y').date()) in ft:\n",
        "                        same_name_count += 1\n",
        "                if same_name_count > 0:\n",
        "                    os.rename(f, 'Spectera_' + str(datetime.datetime.strptime(spectera_rename_re.search(line).group(1), '%m/%d/%Y').date()) + ' (' + str(same_name_count) + ')')\n",
        "                else:\n",
        "                    os.rename(f, 'Spectera_' + str(datetime.datetime.strptime(spectera_rename_re.search(line).group(1), '%m/%d/%Y').date()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JvFvi_2UhD-"
      },
      "source": [
        "Renaming MedMut Sheets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwI4yQ5OUgvp"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/MedMut_Sheets')\n",
        "\n",
        "# Resetting file names\n",
        "for index, f in enumerate(os.listdir()):\n",
        "    os.rename(f, str(index))\n",
        "\n",
        "for f in os.listdir():\n",
        "    with pdfplumber.open(f) as pdf:\n",
        "        for line in pdf.pages[0].extract_text().split('\\n'):\n",
        "            if medmut_rename_re.search(line):\n",
        "                same_name_count = 0\n",
        "                for ft in os.listdir():\n",
        "                    if 'MedMut_' + str(datetime.datetime.strptime(medmut_rename_re.search(line).group(1).zfill(10), '%m-%d-%Y').date()) in ft:\n",
        "                        same_name_count += 1\n",
        "                if same_name_count > 0:\n",
        "                    os.rename(f, 'MedMut_' + str(datetime.datetime.strptime(medmut_rename_re.search(line).group(1), '%m-%d-%Y').date()) + ' (' + str(same_name_count) + ')')\n",
        "                else:\n",
        "                    os.rename(f, 'MedMut_' + str(datetime.datetime.strptime(medmut_rename_re.search(line).group(1), '%m-%d-%Y').date()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Onnxdsy6pTE"
      },
      "source": [
        "Reading in Day Sheets (EyeMed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fpVjpmp6sfw"
      },
      "source": [
        "# Creating the dataframe that will hold all rows of all day sheets\n",
        "day_eyemed = pd.DataFrame(columns=['Patient Name', 'Date of Service', 'Doctor', 'Expected Insurance Payment', 'Claim Number', 'File Name'])\n",
        "os.chdir('/content/drive/MyDrive/Insurance/DaySheets/New Sheets')\n",
        "for f in sorted(os.listdir()):\n",
        "    \n",
        "    current_day_sheet = pd.read_excel(f)\n",
        "\n",
        "    for current_day_sheet_current_row in range(int(current_day_sheet['FIT'][28])):\n",
        "        \n",
        "        # Skipping row if it is not an EyeMed patient\n",
        "        if current_day_sheet['INS CODE'][current_day_sheet_current_row] != 1:\n",
        "            continue\n",
        "        \n",
        "        # Adding optomap to expected insurance payment if necessary\n",
        "        expected_ins_payment = round(current_day_sheet['EXPECTED'][current_day_sheet_current_row])\n",
        "        if current_day_sheet['OPTO'][current_day_sheet_current_row] != 28 and str(current_day_sheet['OPTO'][current_day_sheet_current_row]) != 'nan':\n",
        "            expected_ins_payment += 28 - int(current_day_sheet['OPTO'][current_day_sheet_current_row])\n",
        "        # Appending the current row to the main dataframe\n",
        "        day_eyemed = day_eyemed.append({'Patient Name' : current_day_sheet['FIRST NAME'][current_day_sheet_current_row].strip().upper() + ' ' + current_day_sheet['PATIENT LAST NAME'][current_day_sheet_current_row].strip().upper(), 'Date of Service' : current_day_sheet['DATE'][current_day_sheet_current_row].to_pydatetime().date(), 'Doctor' : dr_dict[current_day_sheet['DR'][current_day_sheet_current_row].upper().strip()], 'Expected Insurance Payment' : expected_ins_payment, 'Claim Number' : current_day_sheet['CLAIM NUMBER'][current_day_sheet_current_row], 'File Name' : f}, ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "day_eyemed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSJvZpbafzjo"
      },
      "source": [
        "Reading in Day Sheets (VSP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXvux5-Af4fX"
      },
      "source": [
        "# Creating the dataframe that will hold all rows of all day sheets\n",
        "day_vsp = pd.DataFrame(columns=['Patient Name', 'Date of Service', 'Doctor', 'Expected Insurance Payment', 'File Name'])\n",
        "os.chdir('/content/drive/MyDrive/Insurance/DaySheets/New Sheets')\n",
        "for f in sorted(os.listdir()):\n",
        "    \n",
        "    current_day_sheet = pd.read_excel(f)\n",
        "    \n",
        "    for current_day_sheet_current_row in range(int(current_day_sheet['FIT'][28])):\n",
        "        \n",
        "        # Skipping row if it is not a VSP patient\n",
        "        if current_day_sheet['INS CODE'][current_day_sheet_current_row] != 2:\n",
        "            continue\n",
        "        \n",
        "        # Adding optomap to expected insurance payment if necessary\n",
        "        expected_ins_payment = round(current_day_sheet['EXPECTED'][current_day_sheet_current_row])\n",
        "        if current_day_sheet['OPTO'][current_day_sheet_current_row] != 28 and str(current_day_sheet['OPTO'][current_day_sheet_current_row]) != 'nan':\n",
        "            expected_ins_payment += 28 - int(current_day_sheet['OPTO'][current_day_sheet_current_row])\n",
        "            print(f)\n",
        "        # Appending the current row to the main dataframe\n",
        "        day_vsp = day_vsp.append({'Patient Name' : current_day_sheet['FIRST NAME'][current_day_sheet_current_row].strip().upper() + ' ' + current_day_sheet['PATIENT LAST NAME'][current_day_sheet_current_row].strip().upper(), 'Date of Service' : current_day_sheet['DATE'][current_day_sheet_current_row].to_pydatetime().date(), 'Doctor' : dr_dict[current_day_sheet['DR'][current_day_sheet_current_row].upper().strip()], 'Expected Insurance Payment' : expected_ins_payment, 'File Name' : f}, ignore_index=True)\n",
        "\n",
        "day_vsp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgM2DF6agxAb"
      },
      "source": [
        "Reading in Day Sheets (Spectera)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqDW9Ri9gwmv"
      },
      "source": [
        "# Creating the dataframe that will hold all rows of all day sheets\n",
        "day_spectera = pd.DataFrame(columns=['Patient Name', 'Date of Service', 'Doctor', 'Expected Insurance Payment', 'Claim Number', 'File Name'])\n",
        "os.chdir('/content/drive/MyDrive/Insurance/DaySheets/New Sheets')\n",
        "for f in sorted(os.listdir()):\n",
        "    \n",
        "    current_day_sheet = pd.read_excel(f)\n",
        "    \n",
        "    for current_day_sheet_current_row in range(int(current_day_sheet['FIT'][28])):\n",
        "        \n",
        "        # Skipping row if it is not a Spectera patient\n",
        "        if current_day_sheet['INS CODE'][current_day_sheet_current_row] != 3:\n",
        "            continue\n",
        "        \n",
        "        # Adding optomap to expected insurance payment if necessary\n",
        "        expected_ins_payment = round(current_day_sheet['EXPECTED'][current_day_sheet_current_row])\n",
        "        if current_day_sheet['OPTO'][current_day_sheet_current_row] != 28 and str(current_day_sheet['OPTO'][current_day_sheet_current_row]) != 'nan':\n",
        "            expected_ins_payment += 28 - int(current_day_sheet['OPTO'][current_day_sheet_current_row])\n",
        "            print(f)\n",
        "        # Appending the current row to the main dataframe\n",
        "        day_spectera = day_spectera.append({'Patient Name' : current_day_sheet['FIRST NAME'][current_day_sheet_current_row].strip().upper() + ' ' + current_day_sheet['PATIENT LAST NAME'][current_day_sheet_current_row].strip().upper(), 'Date of Service' : current_day_sheet['DATE'][current_day_sheet_current_row].to_pydatetime().date(), 'Doctor' : dr_dict[current_day_sheet['DR'][current_day_sheet_current_row].upper().strip()], 'Expected Insurance Payment' : expected_ins_payment, 'Claim Number' : str(current_day_sheet['CLAIM NUMBER'][current_day_sheet_current_row]).upper(), 'File Name' : f}, ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "day_spectera"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O1so3uGiQPd"
      },
      "source": [
        "Reading in Insurance Sheets (EyeMed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIRYspnOiYE2"
      },
      "source": [
        "# Sheets off of Website\n",
        "eyemed_ins_df = pd.DataFrame(columns=['Patient Name', 'Date of Service', 'Insurance Payment', 'Claim Number', 'File Name'])\n",
        "\n",
        "num_failures = 0\n",
        "num_successes = 0\n",
        "successfully_appended_df = True # Setting it to true for the beginning of the loops\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Insurance/EyeMed_Sheets/New EyeMed Sheets')\n",
        "for eyemed_pdf in os.listdir():\n",
        "    with pdfplumber.open(eyemed_pdf) as current_eyemed_pdf:\n",
        "        name_found = False\n",
        "        claim_num_found = False\n",
        "        dos_found = False\n",
        "        payment_found = False\n",
        "        profile = []\n",
        "        for page in current_eyemed_pdf.pages:\n",
        "\n",
        "            for line in page.extract_text().split('\\n'):\n",
        "                \n",
        "                if eyemed_claim_num_re.search(line):\n",
        "\n",
        "                    if not successfully_appended_df:\n",
        "                        num_failures += 1\n",
        "                    else:\n",
        "                        num_successes += 1\n",
        "                    \n",
        "                    profile = []\n",
        "                    profile.append(int(eyemed_claim_num_re.search(line).group(1)))\n",
        "                    profile.append(str(eyemed_pdf))\n",
        "                    \n",
        "                    name_found = False\n",
        "                    claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "                    successfully_appended_df = False\n",
        "                    \n",
        "                    claim_num_found = True\n",
        "\n",
        "                elif eyemed_name_re.search(line) and claim_num_found:\n",
        "                    profile.append(str(eyemed_name_re.search(line).group(2)) + ' ' + str(eyemed_name_re.search(line).group(1)))\n",
        "                    name_found = True\n",
        "                elif eyemed_dos_re.search(line) and not dos_found and name_found and claim_num_found:\n",
        "                    profile.append(datetime.datetime.strptime(str(eyemed_dos_re.search(line).group(1)).strip(), '%m/%d/%y').date())\n",
        "                    dos_found = True\n",
        "                elif eyemed_payments_re.search(line) and name_found and claim_num_found and dos_found:\n",
        "                    profile.append(round(float(eyemed_payments_re.search(line).group(4))))\n",
        "                    payment_found = True\n",
        "\n",
        "                if len(profile) == 5:\n",
        "                    eyemed_ins_df = eyemed_ins_df.append({'Patient Name' : profile[2], 'Claim Number' : profile[0], 'Date of Service' : profile[3], 'Insurance Payment' : profile[4], 'File Name' : profile[1]}, ignore_index=True)\n",
        "                    profile = []\n",
        "                    name_found = False\n",
        "                    claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "\n",
        "                    successfully_appended_df = True\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Sheets that were scanned\n",
        "os.chdir('/content/drive/MyDrive/Insurance/EyeMedMisc_Sheets')\n",
        "\n",
        "successfully_appended_df = True # Setting it to true for the beginning of the loops\n",
        "\n",
        "for scanned_eyemed_pdf_filename in os.listdir():\n",
        "    with pdfplumber.open(scanned_eyemed_pdf_filename) as open_eyemed_pdf:\n",
        "        name_claim_num_found = False\n",
        "        dos_found = False\n",
        "        payment_found = False\n",
        "        profile = []\n",
        "        for page in open_eyemed_pdf.pages:\n",
        "\n",
        "            for line in page.extract_text().split('\\n'):\n",
        "                \n",
        "                if scanned_eyemed_name_claim_num_re.search(line):\n",
        "                    if not successfully_appended_df:\n",
        "                        num_failures += 1\n",
        "                    else:\n",
        "                        num_successes += 1\n",
        "                    \n",
        "                    profile = []\n",
        "                    profile.append(scanned_eyemed_name_claim_num_re.search(line).group(3) + ' ' + scanned_eyemed_name_claim_num_re.search(line).group(2))\n",
        "                    profile.append(scanned_eyemed_name_claim_num_re.search(line).group(1))\n",
        "                    profile.append(scanned_eyemed_pdf_filename)\n",
        "                    name_claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "                    successfully_appended_df = False\n",
        "\n",
        "                    name_claim_num_found = True\n",
        "                \n",
        "                elif scanned_eyemed_dos_re.search(line) and not dos_found and name_claim_num_found:\n",
        "                    profile.append(datetime.datetime.strptime(scanned_eyemed_dos_re.search(line).group(1).strip().zfill(10), '%m/%d/%Y').date())\n",
        "                    dos_found = True\n",
        "                        \n",
        "                elif scanned_eyemed_payments_re.search(line) and dos_found and name_claim_num_found:\n",
        "                    profile.append(scanned_eyemed_payments_re.search(line).group(1))\n",
        "                if len(profile) == 5:\n",
        "                    eyemed_ins_df = eyemed_ins_df.append({'Patient Name' : profile[0], 'Claim Number' : profile[1], 'Date of Service' : profile[3], 'Insurance Payment' : profile[4], 'File Name' : profile[2]}, ignore_index=True)\n",
        "                    profile = []\n",
        "                    name_found = False\n",
        "                    claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "                    successfully_appended_df = True\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VWZlqfOwTVt"
      },
      "source": [
        "eyemed_ins_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWD_t6PViZLh"
      },
      "source": [
        "Reading in Insurance Sheets (VSP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMMBIqgricDk"
      },
      "source": [
        "vsp_ins_df = pd.DataFrame(columns=['Patient Name', 'Date of Service', 'Insurance Payment', 'Claim Number', 'File Name'])\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Insurance/VSP_Sheets/New VSP Sheets')\n",
        "\n",
        "num_failures = 0\n",
        "num_successes = 0\n",
        "successfully_appended_df = True # Setting it to true for the beginning of the loops\n",
        "\n",
        "for vsp_ins_pdf_filename in os.listdir():\n",
        "    with pdfplumber.open(vsp_ins_pdf_filename) as open_vsp_pdf:\n",
        "        name_claim_num_found = False\n",
        "        dos_found = False\n",
        "        payment_found = False\n",
        "        profile = []\n",
        "\n",
        "        for page in open_vsp_pdf.pages:\n",
        "            for line in page.extract_text().split('\\n'):\n",
        "            \n",
        "                if vsp_name_claim_num_re.search(line):\n",
        "                    if not successfully_appended_df:\n",
        "                        num_failures += 1\n",
        "                    else:\n",
        "                        num_successes += 1\n",
        "                    profile = []\n",
        "                    profile.append(str(vsp_name_claim_num_re.search(line).group(2)) + ' ' + str(vsp_name_claim_num_re.search(line).group(1)))\n",
        "                    profile.append(int(vsp_name_claim_num_re.search(line).group(3))) #cn\n",
        "                    profile.append(str(vsp_ins_pdf_filename))\n",
        "\n",
        "                    name_claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "                    \n",
        "                    name_claim_num_found  = True\n",
        "                elif vsp_dos_re.search(line) and not dos_found and name_claim_num_found:\n",
        "                    profile.append(datetime.datetime.strptime(str(vsp_dos_re.search(line).group(1)).strip().zfill(8), '%m/%d/%y').date())\n",
        "                    dos_found = True\n",
        "                elif vsp_payments_re.search(line) and dos_found and name_claim_num_found:\n",
        "                    profile.append(round(float(vsp_payments_re.search(line).group(1))))\n",
        "                    payment_found = True\n",
        "                if len(profile) == 5:\n",
        "                    vsp_ins_df = vsp_ins_df.append({'Patient Name' : profile[0], 'Claim Number' : profile[1], 'Date of Service' : profile[3], 'Insurance Payment' : profile[4], 'File Name' : profile[2]}, ignore_index=True)\n",
        "                    profile = []\n",
        "                    name_claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "                    successfully_appended_df = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSRlLHfBjdCp"
      },
      "source": [
        "vsp_ins_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g9h9-oTicbj"
      },
      "source": [
        "Reading in Insurance Sheets (Spectera)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z65R7m_-ignq"
      },
      "source": [
        "spectera_ins_df = pd.DataFrame(columns=['Patient Name', 'Date of Service', 'Insurance Payment', 'Claim Number', 'File Name'])\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Insurance/Spectera_Sheets/New Spectera Sheets')\n",
        "\n",
        "num_failures = 0\n",
        "num_successes = 0\n",
        "successfully_appended_df = True # Setting it to true for the beginning of the loops\n",
        "\n",
        "for spectera_pdf_filename in os.listdir():\n",
        "    with pdfplumber.open(spectera_pdf_filename) as open_spectera_pdf:\n",
        "        name_found = False\n",
        "        dos_claim_num_found = False\n",
        "        payment_found = False\n",
        "        profile = []\n",
        "        for page in open_spectera_pdf.pages[2:]:\n",
        "            line_list = page.extract_text().split('\\n')\n",
        "            for index, line in enumerate(line_list):\n",
        "                if spectera_name_re.search(line):\n",
        "\n",
        "                    name_found = False\n",
        "                    dos_claim_num_found = False\n",
        "                    payment_found = False\n",
        "                    successfully_appended_df = False\n",
        "                    profile = []\n",
        "                    \n",
        "                    if not spectera_dos_claim_num_re.search(line_list[index + 1]) and spectera_long_name_re.search(line_list[index + 1]):\n",
        "                        on_left_side = False\n",
        "                        for dictionary in page.extract_words(keep_blank_chars=False):\n",
        "                            if spectera_long_name_re.search(line_list[index + 1]).group(1).strip() in dictionary['text'] and dictionary['x0'] < 150:\n",
        "                                profile.append(str(spectera_name_re.search(line).group(1).strip() + ' ' + spectera_long_name_re.search(line_list[index + 1]).group(1).strip()))\n",
        "                                on_left_side = True\n",
        "                        if not on_left_side:\n",
        "                            profile.append(str(spectera_name_re.search(line).group(1).strip()))\n",
        "                    else:\n",
        "                        profile.append(str(spectera_name_re.search(line).group(1).strip()))\n",
        "                    \n",
        "                    profile.append(str(spectera_pdf_filename))\n",
        "\n",
        "                    name_found = True\n",
        "                    \n",
        "                elif spectera_dos_claim_num_re.search(line) and name_found:\n",
        "                    profile.append(datetime.datetime.strptime(str(spectera_dos_claim_num_re.search(line).group(2)), '%m/%d/%Y')) # dos\n",
        "                    profile.append(str(spectera_dos_claim_num_re.search(line).group(1))) # cn\n",
        "                    dos_claim_num_found = True\n",
        "                elif spectera_payments_re.search(line) and dos_claim_num_found and name_found:\n",
        "                    profile.append(round(float(spectera_payments_re.search(line).group(2))))\n",
        "                    payment_found = True\n",
        "                if len(profile) == 5:\n",
        "                    spectera_ins_df = spectera_ins_df.append({'Patient Name' : profile[0], 'Claim Number' : profile[3], 'Date of Service' : profile[2], 'Insurance Payment' : profile[4], 'File Name' : profile[1]}, ignore_index=True)\n",
        "                    profile = []\n",
        "                    name_found = False\n",
        "                    dos_claim_num_found = False\n",
        "                    payment_found = False\n",
        "                    successfully_appended_df = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh6mwG7Q0XxJ"
      },
      "source": [
        "spectera_ins_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBnpJEww1n0-"
      },
      "source": [
        "Reading in Insurance Sheets (MedMut)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flotwNxx1vkJ"
      },
      "source": [
        "medmut_ins_df = pd.DataFrame(columns=['Patient Name', 'Date of Service', 'Insurance Payment', 'Claim Number', 'File Name'])\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Insurance/MedMut_Sheets')\n",
        "\n",
        "num_failures = 0\n",
        "num_successes = 0\n",
        "successfully_appended_df = True # Setting it to true for the beginning of the loops\n",
        "\n",
        "for medmut_ins_pdf_filename in os.listdir():\n",
        "    with pdfplumber.open(medmut_ins_pdf_filename) as open_medmut_pdf:\n",
        "        name_claim_num_found = False\n",
        "        dos_found = False\n",
        "        payment_found = False\n",
        "        profile = []\n",
        "\n",
        "        for page in open_medmut_pdf.pages:\n",
        "            for line in page.extract_text().split('\\n'):\n",
        "            \n",
        "                if medmut_name_claim_num_re.search(line):\n",
        "                    if not successfully_appended_df:\n",
        "                        num_failures += 1\n",
        "                    else:\n",
        "                        num_successes += 1\n",
        "                    profile = []\n",
        "                    profile.append(str(medmut_name_claim_num_re.search(line).group(2)) + ' ' + str(medmut_name_claim_num_re.search(line).group(1)))\n",
        "                    profile.append(int(medmut_name_claim_num_re.search(line).group(3))) #cn\n",
        "                    profile.append(str(medmut_ins_pdf_filename))\n",
        "\n",
        "                    name_claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "                    \n",
        "                    name_claim_num_found  = True\n",
        "                elif medmut_dos_re.search(line) and not dos_found and name_claim_num_found:\n",
        "                    profile.append(datetime.datetime.strptime(str(medmut_dos_re.search(line).group(1)).strip(), '%m/%d/%Y').date())\n",
        "                    dos_found = True\n",
        "                elif medmut_payments_re.search(line) and dos_found and name_claim_num_found:\n",
        "                    profile.append(round(float(medmut_payments_re.search(line).group(1))))\n",
        "                    payment_found = True\n",
        "                if len(profile) == 5:\n",
        "                    medmut_ins_df = medmut_ins_df.append({'Patient Name' : profile[0], 'Claim Number' : profile[1], 'Date of Service' : profile[3], 'Insurance Payment' : profile[4], 'File Name' : profile[2]}, ignore_index=True)\n",
        "                    profile = []\n",
        "                    name_claim_num_found = False\n",
        "                    dos_found = False\n",
        "                    payment_found = False\n",
        "                    successfully_appended_df = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IldWgYSkTx87"
      },
      "source": [
        "medmut_ins_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77x69CPYTwBf"
      },
      "source": [
        "Finding Matches (EyeMed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-QdJPggT5fx"
      },
      "source": [
        "eyemed_matches_df = pd.DataFrame(columns=['Insurance Used', 'Doctor', 'Patient Name (Day Sheet)', 'Patient Name (Insurance)', 'Date of Service (Day Sheet)', 'Date of Service (Insurance)', 'Expected Insurance Payment (Day Sheet)', 'Insurance Payment (Insurance)', 'Claim Number (Day Sheet)', 'Claim Number (Insurance)', 'File Name (Day Sheet)', 'File Name (Insurance)'])\n",
        "eyemed_discs_df = pd.DataFrame(columns=['Resolved?', 'Insurance Payment Not Found', 'Payments Don\\'t Match', 'Insurance Used', 'Doctor', 'Patient Name (Day Sheet)', 'Patient Name (Insurance)', 'Date of Service (Day Sheet)', 'Date of Service (Insurance)', 'Expected Insurance Payment (Day Sheet)', 'Insurance Payment (Insurance)', 'Claim Number (Day Sheet)', 'Claim Number (Insurance)', 'File Name (Day Sheet)', 'File Name (Insurance)'])\n",
        "\n",
        "match_found = True # Set to true so the loop will begin properly\n",
        "for index, current_day_eyemed_row in day_eyemed.iterrows():\n",
        "    for indextwo, current_eyemed_ins_df_row in eyemed_ins_df.iterrows():\n",
        "        # If a match is found\n",
        "        if current_day_eyemed_row['Date of Service'] == current_eyemed_ins_df_row['Date of Service'] and current_day_eyemed_row['Claim Number'] == current_eyemed_ins_df_row['Claim Number']:\n",
        "            match_found = True\n",
        "            if abs(current_day_eyemed_row['Expected Insurance Payment'] - current_eyemed_ins_df_row['Insurance Payment']) <= 1:\n",
        "                eyemed_matches_df = eyemed_matches_df.append({'Insurance Used' : 'Eye Med', 'Doctor' : current_day_eyemed_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_eyemed_row['Patient Name'], 'Patient Name (Insurance)' : current_eyemed_ins_df_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_eyemed_row['Date of Service'], 'Date of Service (Insurance)' : current_eyemed_ins_df_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_eyemed_row['Expected Insurance Payment'], 'Insurance Payment (Insurance)' : current_eyemed_ins_df_row['Insurance Payment'], 'Claim Number (Day Sheet)' : current_day_eyemed_row['Claim Number'], 'Claim Number (Insurance)' : current_eyemed_ins_df_row['Claim Number'], 'File Name (Day Sheet)' : current_day_eyemed_row['File Name'], 'File Name (Insurance)' : current_eyemed_ins_df_row['File Name']}, ignore_index=True)\n",
        "            else:\n",
        "                eyemed_discs_df = eyemed_discs_df.append({'Payments Don\\'t Match' : 'X', 'Insurance Used' : 'Eye Med', 'Doctor' : current_day_eyemed_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_eyemed_row['Patient Name'], 'Patient Name (Insurance)' : current_eyemed_ins_df_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_eyemed_row['Date of Service'], 'Date of Service (Insurance)' : current_eyemed_ins_df_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_eyemed_row['Expected Insurance Payment'], 'Insurance Payment (Insurance)' : current_eyemed_ins_df_row['Insurance Payment'], 'Claim Number (Day Sheet)' : current_day_eyemed_row['Claim Number'], 'Claim Number (Insurance)' : current_eyemed_ins_df_row['Claim Number'], 'File Name (Day Sheet)' : current_day_eyemed_row['File Name'], 'File Name (Insurance)' : current_eyemed_ins_df_row['File Name']}, ignore_index=True)\n",
        "            break\n",
        "\n",
        "    if not match_found:\n",
        "        eyemed_discs_df = eyemed_discs_df.append({'Insurance Payment Not Found' : 'X', 'Insurance Used' : 'Eye Med', 'Doctor' : current_day_eyemed_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_eyemed_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_eyemed_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_eyemed_row['Expected Insurance Payment'], 'Claim Number (Day Sheet)' : current_day_eyemed_row['Claim Number'], 'File Name (Day Sheet)' : current_day_eyemed_row['File Name']}, ignore_index=True)\n",
        "    match_found = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyxnmR4uZymz"
      },
      "source": [
        "Finding Matches (VSP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU9jHBBRZxkd"
      },
      "source": [
        "vsp_matches_df = pd.DataFrame(columns=['Insurance Used', 'Doctor', 'Patient Name (Day Sheet)', 'Patient Name (Insurance)', 'Date of Service (Day Sheet)', 'Date of Service (Insurance)', 'Expected Insurance Payment (Day Sheet)', 'Insurance Payment (Insurance)', 'File Name (Day Sheet)', 'File Name (Insurance)'])\n",
        "vsp_discs_df = pd.DataFrame(columns=['Resolved?', 'Insurance Payment Not Found', 'Payments Don\\'t Match', 'Insurance Used', 'Doctor', 'Patient Name (Day Sheet)', 'Patient Name (Insurance)', 'Date of Service (Day Sheet)', 'Date of Service (Insurance)', 'Expected Insurance Payment (Day Sheet)', 'Insurance Payment (Insurance)', 'File Name (Day Sheet)', 'File Name (Insurance)'])\n",
        "\n",
        "match_found = True # Set to true so the loop will begin properly\n",
        "for index, current_day_vsp_row in day_vsp.iterrows():\n",
        "    for indextwo, current_vsp_ins_df_row in vsp_ins_df.iterrows():\n",
        "        # If a match is found\n",
        "        if match_or_not_vsp(current_day_vsp_row['Patient Name'], current_vsp_ins_df_row['Patient Name'], current_day_vsp_row['Date of Service'], current_vsp_ins_df_row['Date of Service']):\n",
        "            match_found = True\n",
        "            if abs(current_day_vsp_row['Expected Insurance Payment'] - current_vsp_ins_df_row['Insurance Payment']) <= 1:\n",
        "                vsp_matches_df = vsp_matches_df.append({'Insurance Used' : 'VSP', 'Doctor' : current_day_vsp_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_vsp_row['Patient Name'], 'Patient Name (Insurance)' : current_vsp_ins_df_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_vsp_row['Date of Service'], 'Date of Service (Insurance)' : current_vsp_ins_df_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_vsp_row['Expected Insurance Payment'], 'Insurance Payment (Insurance)' : current_vsp_ins_df_row['Insurance Payment'], 'File Name (Day Sheet)' : current_day_vsp_row['File Name'], 'File Name (Insurance)' : current_vsp_ins_df_row['File Name']}, ignore_index=True)\n",
        "            else:\n",
        "                vsp_discs_df = vsp_discs_df.append({'Payments Don\\'t Match' : 'X', 'Insurance Used' : 'VSP', 'Doctor' : current_day_vsp_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_vsp_row['Patient Name'], 'Patient Name (Insurance)' : current_vsp_ins_df_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_vsp_row['Date of Service'], 'Date of Service (Insurance)' : current_vsp_ins_df_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_vsp_row['Expected Insurance Payment'], 'Insurance Payment (Insurance)' : current_vsp_ins_df_row['Insurance Payment'], 'File Name (Day Sheet)' : current_day_vsp_row['File Name'], 'File Name (Insurance)' : current_vsp_ins_df_row['File Name']}, ignore_index=True)\n",
        "            break\n",
        "\n",
        "    if not match_found:\n",
        "        vsp_discs_df = vsp_discs_df.append({'Insurance Payment Not Found' : 'X', 'Insurance Used' : 'VSP', 'Doctor' : current_day_vsp_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_vsp_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_vsp_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_vsp_row['Expected Insurance Payment'], 'File Name (Day Sheet)' : current_day_vsp_row['File Name']}, ignore_index=True)\n",
        "    match_found = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8Rf94OkCoV3"
      },
      "source": [
        "Finding Matches (Spectera)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw3W88WaCqvl"
      },
      "source": [
        "spectera_matches_df = pd.DataFrame(columns=['Insurance Used', 'Doctor', 'Patient Name (Day Sheet)', 'Patient Name (Insurance)', 'Date of Service (Day Sheet)', 'Date of Service (Insurance)', 'Expected Insurance Payment (Day Sheet)', 'Insurance Payment (Insurance)', 'Claim Number (Day Sheet)', 'Claim Number (Insurance)', 'File Name (Day Sheet)', 'File Name (Insurance)'])\n",
        "spectera_discs_df = pd.DataFrame(columns=['Resolved?', 'Insurance Payment Not Found', 'Payments Don\\'t Match', 'Insurance Used', 'Doctor', 'Patient Name (Day Sheet)', 'Patient Name (Insurance)', 'Date of Service (Day Sheet)', 'Date of Service (Insurance)', 'Expected Insurance Payment (Day Sheet)', 'Insurance Payment (Insurance)', 'Claim Number (Day Sheet)', 'Claim Number (Insurance)', 'File Name (Day Sheet)', 'File Name (Insurance)'])\n",
        "\n",
        "match_found = True # Set to true so the loop will begin properly\n",
        "for index, current_day_spectera_row in day_spectera.iterrows():\n",
        "    for indextwo, current_spectera_ins_df_row in spectera_ins_df.iterrows():\n",
        "        # If a match is found\n",
        "        if current_day_spectera_row['Date of Service'] == current_spectera_ins_df_row['Date of Service'] and current_day_spectera_row['Claim Number'] == current_spectera_ins_df_row['Claim Number']:\n",
        "            match_found = True\n",
        "            if abs(current_day_spectera_row['Expected Insurance Payment'] - current_spectera_ins_df_row['Insurance Payment']) <= 1:\n",
        "                spectera_matches_df = spectera_matches_df.append({'Insurance Used' : 'Eye Med', 'Doctor' : current_day_spectera_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_spectera_row['Patient Name'], 'Patient Name (Insurance)' : current_spectera_ins_df_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_spectera_row['Date of Service'], 'Date of Service (Insurance)' : current_spectera_ins_df_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_spectera_row['Expected Insurance Payment'], 'Insurance Payment (Insurance)' : current_spectera_ins_df_row['Insurance Payment'], 'Claim Number (Day Sheet)' : current_day_spectera_row['Claim Number'], 'Claim Number (Insurance)' : current_spectera_ins_df_row['Claim Number'], 'File Name (Day Sheet)' : current_day_spectera_row['File Name'], 'File Name (Insurance)' : current_spectera_ins_df_row['File Name']}, ignore_index=True)\n",
        "            else:\n",
        "                spectera_discs_df = spectera_discs_df.append({'Payments Don\\'t Match' : 'X', 'Insurance Used' : 'Eye Med', 'Doctor' : current_day_spectera_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_spectera_row['Patient Name'], 'Patient Name (Insurance)' : current_spectera_ins_df_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_spectera_row['Date of Service'], 'Date of Service (Insurance)' : current_spectera_ins_df_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_spectera_row['Expected Insurance Payment'], 'Insurance Payment (Insurance)' : current_spectera_ins_df_row['Insurance Payment'], 'Claim Number (Day Sheet)' : current_day_spectera_row['Claim Number'], 'Claim Number (Insurance)' : current_spectera_ins_df_row['Claim Number'], 'File Name (Day Sheet)' : current_day_spectera_row['File Name'], 'File Name (Insurance)' : current_spectera_ins_df_row['File Name']}, ignore_index=True)\n",
        "            break\n",
        "\n",
        "    if not match_found:\n",
        "        spectera_discs_df = spectera_discs_df.append({'Insurance Payment Not Found' : 'X', 'Insurance Used' : 'Eye Med', 'Doctor' : current_day_spectera_row['Doctor'],  'Patient Name (Day Sheet)' : current_day_spectera_row['Patient Name'], 'Date of Service (Day Sheet)' : current_day_spectera_row['Date of Service'], 'Expected Insurance Payment (Day Sheet)' : current_day_spectera_row['Expected Insurance Payment'], 'Claim Number (Day Sheet)' : current_day_spectera_row['Claim Number'], 'File Name (Day Sheet)' : current_day_spectera_row['File Name']}, ignore_index=True)\n",
        "    match_found = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zauvWwFiHSqj"
      },
      "source": [
        "spectera_matches_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V5LEc9MMGSO"
      },
      "source": [
        "Exporting EyeMed Excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-QsQTH5MLwN"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/Disc Sheets/')\n",
        "\n",
        "date_series = sorted(eyemed_matches_df['Date of Service (Day Sheet)'].append(eyemed_discs_df['Date of Service (Day Sheet)']))\n",
        "name_excel_add_str = '_' + str(date_series[0]) + '_through_' + str(date_series[-1])\n",
        "\n",
        "eyemed_matches_df.to_excel('EyeMed_Matches' + name_excel_add_str + '.xlsx')\n",
        "eyemed_discs_df.to_excel('EyeMed_Discs' + name_excel_add_str + '.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6CYl9YgMMLp"
      },
      "source": [
        "Exporting VSP Excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8SMnxkAMOkM"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/Disc Sheets/')\n",
        "\n",
        "date_series = sorted(vsp_matches_df['Date of Service (Day Sheet)'].append(vsp_discs_df['Date of Service (Day Sheet)']))\n",
        "name_excel_add_str = '_' + str(date_series[0]) + '_through_' + str(date_series[-1])\n",
        "\n",
        "vsp_matches_df.to_excel('vsp_Matches' + name_excel_add_str + '.xlsx')\n",
        "vsp_discs_df.to_excel('vsp_Discs' + name_excel_add_str + '.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dbZxnfXMO5C"
      },
      "source": [
        "Exporting Spectera Excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b94rNm2MRp-"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/Disc Sheets/')\n",
        "\n",
        "date_series = sorted(spectera_matches_df['Date of Service (Day Sheet)'].append(spectera_discs_df['Date of Service (Day Sheet)']))\n",
        "name_excel_add_str = '_' + str(date_series[0]) + '_through_' + str(date_series[-1])\n",
        "\n",
        "spectera_matches_df.to_excel('spectera_Matches' + name_excel_add_str + '.xlsx')\n",
        "spectera_discs_df.to_excel('spectera_Discs' + name_excel_add_str + '.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r5tbComMSFZ"
      },
      "source": [
        "Exporting MedMut Excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypFx458MMV8K"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Insurance/Disc Sheets/')\n",
        "\n",
        "date_series = sorted(medmut_matches_df['Date of Service (Day Sheet)'].append(medmut_discs_df['Date of Service (Day Sheet)']))\n",
        "name_excel_add_str = '_' + str(date_series[0]) + '_through_' + str(date_series[-1])\n",
        "\n",
        "medmut_matches_df.to_excel('medmut_Matches' + name_excel_add_str + '.xlsx')\n",
        "medmut_discs_df.to_excel('medmut_Discs' + name_excel_add_str + '.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}